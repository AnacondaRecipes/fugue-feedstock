{% set name = "fugue" %}
{% set version = "0.6.6" %}


package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/fugue-{{ version }}.tar.gz
  sha256: 270ff2bf638539ceea2c3bb1a2756b66a891b528eb3cf380c1e469fe157362d4

build:
  number: 0
  noarch: python
  script: {{ PYTHON }} -m pip install . -vv

requirements:
  host:
    - pip
    - python >=3.6
  run:
    - adagio >=0.2.3
    - antlr4-python3-runtime >=4.9,<4.10
    - importlib-metadata
    - pandas >=1.0.2
    - pyarrow >=0.15.1
    - python >=3.6
    - qpd >=0.2.6
    - sqlalchemy
    - triad >=0.6.0

test:
  imports:
    - fugue
    - fugue.collections
    - fugue.column
    - fugue.dataframe
    - fugue.execution
    - fugue.execution.creator
    - fugue.execution.outputter
    - fugue.execution.processor
    - fugue.execution.transformer
    - fugue.extensions
    - fugue.extensions.creator
    - fugue.extensions.outputter
    - fugue.extensions.processor
    - fugue.extensions.transformer
    - fugue.rpc
    - fugue.workflow
  commands:
    - pip check
  requires:
    - pip

about:
  home: http://github.com/fugue-project/fugue
  summary: An abstraction layer for distributed computation
  license: Apache-2.0
  license_file: LICENSE  # license file manually packaged.
  description: |
    Fugue is a unified interface for distributed computing that lets
     users execute Python, pandas, and SQL code on Spark and Dask
     without rewrites. It is meant for data scientists/analysts who want
     to focus on defining logic rather than worrying about execution. It
     is also suitable for SQL users wanting to use SQL to define
     end-to-end workflows in pandas, Spark, and Dask. Data scientists
     using pandas wanting to take advantage of Spark or Dask with
     minimal effort, as well as big data practitioners finding testing
     code to be costly and slow would also find Fugue useful.


extra:
  recipe-maintainers:
    - thewchan
