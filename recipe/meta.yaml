{% set name = "fugue" %}
{% set version = "0.9.4" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://github.com/fugue-project/{{ name }}/archive/refs/tags/{{ version }}.tar.gz
  sha256: 31e3d33e71d5e583d1b602759534ffb4a4221faa26271e0044629251c032e32a

build:
  number: 0
  skip: true  # [py<38]
  script: {{ PYTHON }} -m pip install . --no-deps --no-build-isolation --ignore-installed -vvv

requirements:
  host:
    - pip
    - python
    - setuptools
    - wheel
  run:
    - python
    - triad >=1.0.0
    - adagio >=0.2.6
  run_constrained:
    # sql dependencies
    - qpd >=0.4.4
    - fugue-sql-antlr >=0.2.0
    - sqlglot <28.0.0
    - pyspark >=3.1.1
    - dask-core >=2024.4.0
    - pyarrow >=7.0.0
    - pandas >=2.0.2
    - ray >=2.30
    - python-duckdb >=0.5.0
    - ipython >=7.10.0

# assert self.context.name.startswith("pandas")
# assert self.engine.conf["fugue.test.dummy"] == "dummy"
{% set tests_to_skip = "test_with_backend_with_context[pandas]" %}
{% set tests_to_skip = tests_to_skip + " or test_properties[pandas]" %}

test:
  source_files:
    - tests
  imports:
    - fugue
    - fugue._utils
    - fugue.api
    - fugue.bag
    - fugue.collections
    - fugue.column
    - fugue.constants
    - fugue.dataframe
    - fugue.dataset
    - fugue.dev
    - fugue.exceptions
    - fugue.execution
    - fugue.extensions
    - fugue.plugins
    - fugue.registry
    - fugue.rpc
    - fugue.sql
    - fugue.workflow
  requires:
    - pip
    - pytest
    - python-duckdb >=0.5.0
    - sqlglot
    - s3fs
    - matplotlib-base
    - cloudpickle
  commands:
    - pip check
    - python -c "from importlib.metadata import version; assert(version('{{ name }}')=='{{ version }}')"
    - pytest -v tests/fugue -k "not({{ tests_to_skip }})"

about:
  home: https://github.com/fugue-project/fugue
  summary: An abstraction layer for distributed computation
  license: Apache-2.0
  license_family: Apache
  license_file: LICENSE
  description: |
    Fugue is a unified interface for distributed computing that lets
    users execute Python, pandas, and SQL code on Spark and Dask
    without rewrites. It is meant for data scientists/analysts who want
    to focus on defining logic rather than worrying about execution. It
    is also suitable for SQL users wanting to use SQL to define
    end-to-end workflows in pandas, Spark, and Dask. Data scientists
    using pandas wanting to take advantage of Spark or Dask with
    minimal effort, as well as big data practitioners finding testing
    code to be costly and slow would also find Fugue useful.
  doc_url: https://fugue-tutorials.readthedocs.io
  dev_url: https://github.com/fugue-project/fugue

extra:
  recipe-maintainers:
    - kvnkho
    - goodwanghan
    - charlesbluca
    - thewchan